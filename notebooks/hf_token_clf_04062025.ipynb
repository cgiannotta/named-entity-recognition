{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03099020",
   "metadata": {},
   "source": [
    "# Hugging Face NER\n",
    "\n",
    "[NER Tutorial](https://huggingface.co/learn/llm-course/en/chapter7/2)\n",
    "\n",
    "Uses the [CoNLL-2003 dataset](https://huggingface.co/datasets/conll2003), which has news stories from Reuters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6d3cf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# !pip install datasets transformers\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c006128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 983k/983k [00:00<00:00, 3.10MB/s]\n",
      "Generating train split: 100%|██████████| 14041/14041 [00:02<00:00, 4762.92 examples/s]\n",
      "Generating validation split: 100%|██████████| 3250/3250 [00:00<00:00, 3800.48 examples/s]\n",
      "Generating test split: 100%|██████████| 3453/3453 [00:00<00:00, 4592.02 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"conll2003\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd1cf4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "259d643b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id :  0\n",
      "tokens :  ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
      "pos_tags :  [22, 42, 16, 21, 35, 37, 16, 21, 7]\n",
      "chunk_tags :  [11, 21, 11, 12, 21, 22, 11, 12, 0]\n",
      "ner_tags :  [3, 0, 7, 0, 0, 0, 7, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# look at single text\n",
    "sample = raw_datasets[\"train\"][0]\n",
    "for k, v in sample.items():\n",
    "    print(k, \": \", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e15d7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\n",
    "ner_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f56e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O means the word doesn’t correspond to any entity.\n",
    "# B-PER/I-PER means the word corresponds to the beginning of/is inside a person entity.\n",
    "# B-ORG/I-ORG means the word corresponds to the beginning of/is inside an organization entity.\n",
    "# B-LOC/I-LOC means the word corresponds to the beginning of/is inside a location entity.\n",
    "# B-MISC/I-MISC means the word corresponds to the beginning of/is inside a miscellaneous entity.\n",
    "\n",
    "label_names = ner_feature.feature.names\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da1921fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14041"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa2f438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7046"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e5048ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Securities and   Exchange Commission acts to improve stock-trade prices for investors . \n",
      "O B-ORG      I-ORG I-ORG    I-ORG      O    O  O       O           O      O   O         O \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "idx = random.choice(range(len(raw_datasets[\"train\"])))\n",
    "words = raw_datasets[\"train\"][idx][\"tokens\"]\n",
    "labels = raw_datasets[\"train\"][idx][\"ner_tags\"]\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = label_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7557e70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c27ac0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs6035_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
